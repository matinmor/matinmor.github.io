[{"Qnum": 0, "Question": "what are sitting on the counter in different stages of cutting with a knife?", "out": ["1. Image 2 shows a person cutting an apple on a wooden cutting board.", "2. The person is using a knife to slice the apple into pieces on the cutting board.", "3. The apple is placed on the left side of the cutting board, while the person is on the right cutting the fruit with a knife."], "CS_val": ["0.9870395064353943", "subjective", "0.7018598318099976"], "CS_val_2": ["0.9870395064353943", "0.9868398904800415", "0.7018598318099976"], "img_dir": ["img_db_CS/image_qs0_0.png", "img_db_CS/image_qs0_1.png", "img_db_CS/image_qs0_2.png", "img_db_CS/image_qs0_3.png", "img_db_CS/image_qs0_4.png"]}, {"Qnum": 1, "Question": "where does the person sit next to a top with a hat on?", "out": ["1. The person in the image is sitting on a bench.", "2. The person is wearing a yellow dress.", "3. The person is also wearing a hat."], "CS_val": ["0.8499487042427063", "subjective", "subjective"], "CS_val_2": ["0.8499487042427063", "0.9998416900634766", "0.9800432920455933"], "img_dir": ["img_db_CS/image_qs1_0.png", "img_db_CS/image_qs1_1.png", "img_db_CS/image_qs1_2.png", "img_db_CS/image_qs1_3.png", "img_db_CS/image_qs1_4.png"]}, {"Qnum": 2, "Question": "what are standing in tall dry grass look at the tourists?", "out": ["1. A giraffe is spotted in a group of images standing in tall dry grass.", "2. The giraffe is observed to be looking at the tourists."], "CS_val": ["0.2696073055267334", "subjective"], "CS_val_2": ["0.2696073055267334", "0.00801248662173748"], "img_dir": ["img_db_CS/image_qs2_0.png", "img_db_CS/image_qs2_1.png", "img_db_CS/image_qs2_2.png", "img_db_CS/image_qs2_3.png", "img_db_CS/image_qs2_4.png"]}, {"Qnum": 3, "Question": "the man carrying what runs into the ocean?", "out": ["1. A man in a group of images is seen running into the ocean while carrying a surfboard.", "2. A man is running into the ocean with a surfboard."], "CS_val": ["subjective", "0.35451287031173706"], "CS_val_2": ["0.049724724143743515", "0.35451287031173706"], "img_dir": ["img_db_CS/image_qs3_0.png", "img_db_CS/image_qs3_1.png", "img_db_CS/image_qs3_2.png", "img_db_CS/image_qs3_3.png", "img_db_CS/image_qs3_4.png"]}, {"Qnum": 4, "Question": "what is playing with the large chunk of ice?", "out": ["1. A polar bear is seen playing with a large chunk of ice in a group of images.", "2. The polar bear is standing on snow-covered ground close to the chunk of ice.", "3. The chunk of ice resembles a toy or sports ball.", "4. The scene demonstrates the playful and curious nature of the bear as it interacts with its surroundings."], "CS_val": ["0.07001464068889618", "subjective", "subjective", "subjective"], "CS_val_2": ["0.07001464068889618", "0.9058545231819153", "0.9237837791442871", "0.9897559285163879"], "img_dir": ["img_db_CS/image_qs4_0.png", "img_db_CS/image_qs4_1.png", "img_db_CS/image_qs4_2.png", "img_db_CS/image_qs4_3.png", "img_db_CS/image_qs4_4.png"]}, {"Qnum": 5, "Question": "what covered in white linen in a bedroom with a dresser?", "out": ["1. There is a bedroom in a group of images with a bed covered in white linen and a dresser.", "2. The bedroom's bed is covered in white linen.", "3. The bed in the bedroom is covered in white linen.", "4. The bedroom includes a dresser."], "CS_val": ["subjective", "0.0086471326649189", "0.014676530845463276", "subjective"], "CS_val_2": ["0.5358318090438843", "0.0086471326649189", "0.014676530845463276", "0.9960654377937317"], "img_dir": ["img_db_CS/image_qs5_0.png", "img_db_CS/image_qs5_1.png", "img_db_CS/image_qs5_2.png", "img_db_CS/image_qs5_3.png", "img_db_CS/image_qs5_4.png"]}, {"Qnum": 6, "Question": "what is the color of the airplane?", "out": ["1. The airplane in the group of images is colored white and red.", "2. The airplane itself is colored white and red."], "CS_val": ["subjective", "0.9537777900695801"], "CS_val_2": ["0.5975131392478943", "0.9537777900695801"], "img_dir": ["img_db_CS/image_qs6_0.png", "img_db_CS/image_qs6_1.png", "img_db_CS/image_qs6_2.png", "img_db_CS/image_qs6_3.png", "img_db_CS/image_qs6_4.png"]}, {"Qnum": 7, "Question": "what is parked on the side of the grass?", "out": ["A red pickup truck is parked on the side of the grass in a group of images."], "CS_val": ["0.1258402019739151"], "CS_val_2": ["0.1258402019739151"], "img_dir": ["img_db_CS/image_qs7_0.png", "img_db_CS/image_qs7_1.png", "img_db_CS/image_qs7_2.png", "img_db_CS/image_qs7_3.png", "img_db_CS/image_qs7_4.png"]}, {"Qnum": 8, "Question": "what are sitting on top of wood poles?", "out": ["1. A black bird is perched on a metal pipe in a group of images. ", "2. The bird is observing its surroundings while perched on the pipe."], "CS_val": ["0.20231537520885468", "subjective"], "CS_val_2": ["0.20231537520885468", "0.9992929697036743"], "img_dir": ["img_db_CS/image_qs8_0.png", "img_db_CS/image_qs8_1.png", "img_db_CS/image_qs8_2.png", "img_db_CS/image_qs8_3.png", "img_db_CS/image_qs8_4.png"]}, {"Qnum": 9, "Question": "what is the color of the kitten?", "out": ["The kitten in the group of images is brown and white."], "CS_val": ["0.43996480107307434"], "CS_val_2": ["0.43996480107307434"], "img_dir": ["img_db_CS/image_qs9_0.png", "img_db_CS/image_qs9_1.png", "img_db_CS/image_qs9_2.png", "img_db_CS/image_qs9_3.png", "img_db_CS/image_qs9_4.png"]}, {"Qnum": 10, "Question": "what is the color of the plate?", "out": ["1. The plate in the group of images is white."], "CS_val": ["0.8393746614456177"], "CS_val_2": ["0.8393746614456177"], "img_dir": ["img_db_CS/image_qs10_0.png", "img_db_CS/image_qs10_1.png", "img_db_CS/image_qs10_2.png", "img_db_CS/image_qs10_3.png", "img_db_CS/image_qs10_4.png"]}, {"Qnum": 11, "Question": "what are sitting on the wooden perch over grass and bushes?", "out": ["1. A wooden bench is placed on a wooden perch above grass and bushes in a group of images.", "2. The scene depicted shows a wooden bench resting on a wooden perch, surrounded by grass and bushes.", "3. A wooden bench is positioned on a wooden perch, with grass and bushes underneath, as shown in the images."], "CS_val": ["subjective", "0.061213359236717224", "0.0005163997411727905"], "CS_val_2": ["0.012204228900372982", "0.061213359236717224", "0.0005163997411727905"], "img_dir": ["img_db_CS/image_qs11_0.png", "img_db_CS/image_qs11_1.png", "img_db_CS/image_qs11_2.png", "img_db_CS/image_qs11_3.png", "img_db_CS/image_qs11_4.png"]}, {"Qnum": 12, "Question": "what stands in the rocky area , larger rocks behind him?", "out": ["1. A brown bear is standing in a rocky area in the image.", "2. The rocky area where the brown bear is located has larger rocks behind it."], "CS_val": ["0.995618999004364", "0.9866570830345154"], "CS_val_2": ["0.995618999004364", "0.9866570830345154"], "img_dir": ["img_db_CS/image_qs12_0.png", "img_db_CS/image_qs12_1.png", "img_db_CS/image_qs12_2.png", "img_db_CS/image_qs12_3.png", "img_db_CS/image_qs12_4.png"]}, {"Qnum": 13, "Question": "what are rubbing their heads and necks together?", "out": ["1. Dogs in the group of images are seen rubbing their heads and necks together.", "2. The dogs are observed engaging in head and neck rubbing behavior.", "3. Dogs in the group are interacting by rubbing their heads and necks together."], "CS_val": ["0.0043909186497330666", "subjective", "subjective"], "CS_val_2": ["0.0043909186497330666", "0.08939289301633835", "0.12802593410015106"], "img_dir": ["img_db_CS/image_qs13_0.png", "img_db_CS/image_qs13_1.png", "img_db_CS/image_qs13_2.png", "img_db_CS/image_qs13_3.png", "img_db_CS/image_qs13_4.png"]}, {"Qnum": 14, "Question": "what is the color of the freezer?", "out": ["The freezer in the group of images is black and white in color."], "CS_val": ["0.02488677203655243"], "CS_val_2": ["0.02488677203655243"], "img_dir": ["img_db_CS/image_qs14_0.png", "img_db_CS/image_qs14_1.png", "img_db_CS/image_qs14_2.png", "img_db_CS/image_qs14_3.png", "img_db_CS/image_qs14_4.png"]}, {"Qnum": 15, "Question": "what is laying next to a book shelf filled with books?", "out": ["1. Stuffed animal next to book shelf with books in group of images.", "2. Stuffed animal next to full book shelf.", "3. Stuffed animal positioned by book shelf of books.", "4. Full book shelf with many books."], "CS_val": ["0.11076167225837708", "subjective", "subjective", "0.32301291823387146"], "CS_val_2": ["0.11076167225837708", "0.23458795249462128", "0.8029139637947083", "0.32301291823387146"], "img_dir": ["img_db_CS/image_qs15_0.png", "img_db_CS/image_qs15_1.png", "img_db_CS/image_qs15_2.png", "img_db_CS/image_qs15_3.png", "img_db_CS/image_qs15_4.png"]}, {"Qnum": 16, "Question": "what are standing in the grassy field?", "out": ["1. Two white sheep are in the group of images.", "2. A black and white cow is present in the images.", "3. A large brown horse stands in a grassy field."], "CS_val": ["0.5553928017616272", "0.6746895909309387", "subjective"], "CS_val_2": ["0.5553928017616272", "0.6746895909309387", "0.9937730431556702"], "img_dir": ["img_db_CS/image_qs16_0.png", "img_db_CS/image_qs16_1.png", "img_db_CS/image_qs16_2.png", "img_db_CS/image_qs16_3.png", "img_db_CS/image_qs16_4.png"]}, {"Qnum": 17, "Question": "what are flying through the sky?", "out": ["1. Two flying objects are present among a group of images.", "2. An airplane is currently flying through the sky.", "3. A bird is also seen flying through the sky."], "CS_val": ["0.05015653744339943", "0.9998811483383179", "subjective"], "CS_val_2": ["0.05015653744339943", "0.9998811483383179", "0.042249295860528946"], "img_dir": ["img_db_CS/image_qs17_0.png", "img_db_CS/image_qs17_1.png", "img_db_CS/image_qs17_2.png", "img_db_CS/image_qs17_3.png", "img_db_CS/image_qs17_4.png"]}, {"Qnum": 18, "Question": "what filled with the variety of food?", "out": ["1. Image 1 contains a variety of food.", "2. The tray in the image includes a bagel, eggs, and fruit.", "3. The bagel in the image is cut in half.", "4. The tray is placed on a dining table with a green polka dot tablecloth."], "CS_val": ["0.9977489113807678", "0.9658556580543518", "0.9998874664306641", "0.9555701017379761"], "CS_val_2": ["0.9977489113807678", "0.9658556580543518", "0.9998874664306641", "0.9555701017379761"], "img_dir": ["img_db_CS/image_qs18_0.png", "img_db_CS/image_qs18_1.png", "img_db_CS/image_qs18_2.png", "img_db_CS/image_qs18_3.png", "img_db_CS/image_qs18_4.png"]}, {"Qnum": 19, "Question": "people standing on the street holding what?", "out": ["People in the images are standing on the street and using umbrellas."], "CS_val": ["0.9808263778686523"], "CS_val_2": ["0.9808263778686523"], "img_dir": ["img_db_CS/image_qs19_0.png", "img_db_CS/image_qs19_1.png", "img_db_CS/image_qs19_2.png", "img_db_CS/image_qs19_3.png", "img_db_CS/image_qs19_4.png"]}, {"Qnum": 20, "Question": "what is the man in the black leather coat holding?", "out": ["A man in a black leather coat is holding a handbag in a group of images."], "CS_val": ["0.0002338701015105471"], "CS_val_2": ["0.0002338701015105471"], "img_dir": ["img_db_CS/image_qs20_0.png", "img_db_CS/image_qs20_1.png", "img_db_CS/image_qs20_2.png", "img_db_CS/image_qs20_3.png", "img_db_CS/image_qs20_4.png"]}, {"Qnum": 21, "Question": "what does the view of a street at night show?", "out": ["1. Nighttime street scene captures bustling urban environment with lively atmosphere.", "2. Streetlights illuminate street with people walking around, some carrying handbags.", "3. Urban setting highlighted by cars, parking meters, and traffic lights.", "4. Busy street with pedestrians creates energetic vibe, representing vibrant city at night."], "CS_val": ["subjective", "0.8719332218170166", "0.9755791425704956", "0.9579983353614807"], "CS_val_2": ["0.9905615448951721", "0.8719332218170166", "0.9755791425704956", "0.9579983353614807"], "img_dir": ["img_db_CS/image_qs21_0.png", "img_db_CS/image_qs21_1.png", "img_db_CS/image_qs21_2.png", "img_db_CS/image_qs21_3.png", "img_db_CS/image_qs21_4.png"]}, {"Qnum": 22, "Question": "what is lying on the concrete surface?", "out": ["1. A wooden bench is resting on a concrete surface among a group of images."], "CS_val": ["0.7184414267539978"], "CS_val_2": ["0.7184414267539978"], "img_dir": ["img_db_CS/image_qs22_0.png", "img_db_CS/image_qs22_1.png", "img_db_CS/image_qs22_2.png", "img_db_CS/image_qs22_3.png", "img_db_CS/image_qs22_4.png"]}, {"Qnum": 23, "Question": "what is the color of the jacket?", "out": ["The jacket in the group of images is black and white in color."], "CS_val": ["0.10803759098052979"], "CS_val_2": ["0.10803759098052979"], "img_dir": ["img_db_CS/image_qs23_0.png", "img_db_CS/image_qs23_1.png", "img_db_CS/image_qs23_2.png", "img_db_CS/image_qs23_3.png", "img_db_CS/image_qs23_4.png"]}, {"Qnum": 24, "Question": "what is going down the street?", "out": ["1. Motorcyclists are riding down the street in a group of images.", "2. The motorcyclists are riding motorcycles.", "3. Safety helmets are being worn by the motorcyclists.", "4. The group of motorcyclists is traveling in a straight line.", "5. Some of the motorcyclists are wearing colorful jackets."], "CS_val": ["0.8641958236694336", "0.990723192691803", "0.5572580099105835", "0.7834250330924988", "subjective"], "CS_val_2": ["0.8641958236694336", "0.990723192691803", "0.5572580099105835", "0.7834250330924988", "0.16204027831554413"], "img_dir": ["img_db_CS/image_qs24_0.png", "img_db_CS/image_qs24_1.png", "img_db_CS/image_qs24_2.png", "img_db_CS/image_qs24_3.png", "img_db_CS/image_qs24_4.png"]}, {"Qnum": 25, "Question": "what filled with tooth brushes on top of a counter?", "out": ["There is a scene with a toothbrush holder filled with toothbrushes on a counter among a group of images."], "CS_val": ["0.19837328791618347"], "CS_val_2": ["0.19837328791618347"], "img_dir": ["img_db_CS/image_qs25_0.png", "img_db_CS/image_qs25_1.png", "img_db_CS/image_qs25_2.png", "img_db_CS/image_qs25_3.png", "img_db_CS/image_qs25_4.png"]}, {"Qnum": 26, "Question": "what does the giraffe lick at the zoo?", "out": ["1. Multiple images are presented in a group for analysis or comparison.", "2. A giraffe is observed licking the ground in a specific location, identified as <image3>, within a zoo."], "CS_val": ["subjective", "0.8637517690658569"], "CS_val_2": ["0.5563681125640869", "0.8637517690658569"], "img_dir": ["img_db_CS/image_qs26_0.png", "img_db_CS/image_qs26_1.png", "img_db_CS/image_qs26_2.png", "img_db_CS/image_qs26_3.png", "img_db_CS/image_qs26_4.png"]}, {"Qnum": 27, "Question": "what are face to face along side a roadway?", "out": ["1. A man is riding a motorcycle on a highway in a group of images.", "2. A car is following the man on the motorcycle.", "3. The motorcycle and car are facing each other on the roadway."], "CS_val": ["0.5568963885307312", "0.40512415766716003", "subjective"], "CS_val_2": ["0.5568963885307312", "0.40512415766716003", "subjective"], "img_dir": ["img_db_CS/image_qs27_0.png", "img_db_CS/image_qs27_1.png", "img_db_CS/image_qs27_2.png", "img_db_CS/image_qs27_3.png", "img_db_CS/image_qs27_4.png"]}, {"Qnum": 28, "Question": "where does the dog sniff some food?", "out": ["1. The dog in image1 is actively sniffing some food. ", "2. The dog is standing in a kitchen, looking into an open refrigerator, showing curiosity about the contents inside."], "CS_val": ["0.029365677386522293", "0.6874580383300781"], "CS_val_2": ["0.029365677386522293", "0.6874580383300781"], "img_dir": ["img_db_CS/image_qs28_0.png", "img_db_CS/image_qs28_1.png", "img_db_CS/image_qs28_2.png", "img_db_CS/image_qs28_3.png", "img_db_CS/image_qs28_4.png"]}, {"Qnum": 29, "Question": "the woman with a hat , tie and striped halter smoking what?", "out": ["A woman in a hat, tie, and striped halter is smoking a cigarette in the group of images."], "CS_val": ["0.9055083990097046"], "CS_val_2": ["0.9055083990097046"], "img_dir": ["img_db_CS/image_qs29_0.png", "img_db_CS/image_qs29_1.png", "img_db_CS/image_qs29_2.png", "img_db_CS/image_qs29_3.png", "img_db_CS/image_qs29_4.png"]}, {"Qnum": 30, "Question": "what is covered with rust?", "out": ["1. A group of images is being analyzed for a specific purpose.", "2. The old truck is in poor condition and heavily affected by rust."], "CS_val": ["0.9247942566871643", "subjective"], "CS_val_2": ["0.9247942566871643", "0.9740095734596252"], "img_dir": ["img_db_CS/image_qs30_0.png", "img_db_CS/image_qs30_1.png", "img_db_CS/image_qs30_2.png", "img_db_CS/image_qs30_3.png", "img_db_CS/image_qs30_4.png"]}, {"Qnum": 31, "Question": "what is the color of the barns?", "out": ["Summary: The barns in the group of images are all painted red."], "CS_val": ["0.6668961048126221"], "CS_val_2": ["0.6668961048126221"], "img_dir": ["img_db_CS/image_qs31_0.png", "img_db_CS/image_qs31_1.png", "img_db_CS/image_qs31_2.png", "img_db_CS/image_qs31_3.png", "img_db_CS/image_qs31_4.png"]}, {"Qnum": 32, "Question": "what sits among floral decorations?", "out": ["1. Wooden bookshelf in a group of images has a wheat plant or straw flower among floral decorations.", "2. Wood bookshelf with wheat plant or straw flower among floral decorations.", "3. Wooden bookshelf includes wheat plant or straw flower among floral decorations.", "4. Wheat plant or straw flower placed among floral decorations on wooden bookshelf."], "CS_val": ["subjective", "0.9662845730781555", "0.9963490962982178", "0.9776736497879028"], "CS_val_2": ["0.9493501782417297", "0.9662845730781555", "0.9963490962982178", "0.9776736497879028"], "img_dir": ["img_db_CS/image_qs32_0.png", "img_db_CS/image_qs32_1.png", "img_db_CS/image_qs32_2.png", "img_db_CS/image_qs32_3.png", "img_db_CS/image_qs32_4.png"]}, {"Qnum": 33, "Question": "what is laying on top of a large rock?", "out": ["A brown bear is resting on a large rock in a group of images."], "CS_val": ["0.986027717590332"], "CS_val_2": ["0.986027717590332"], "img_dir": ["img_db_CS/image_qs33_0.png", "img_db_CS/image_qs33_1.png", "img_db_CS/image_qs33_2.png", "img_db_CS/image_qs33_3.png", "img_db_CS/image_qs33_4.png"]}, {"Qnum": 34, "Question": "what lined up on tarmac with landing gear in sunny day?", "out": ["1. A large airplane is seen parked on the tarmac with its landing gear down in a group of images.", "2. The weather is sunny when the airplane is seen."], "CS_val": ["subjective", "0.6089252233505249"], "CS_val_2": ["0.19775444269180298", "0.6089252233505249"], "img_dir": ["img_db_CS/image_qs34_0.png", "img_db_CS/image_qs34_1.png", "img_db_CS/image_qs34_2.png", "img_db_CS/image_qs34_3.png", "img_db_CS/image_qs34_4.png"]}, {"Qnum": 35, "Question": "what is being transported in the truck down a road?", "out": ["1. A man is riding a motorcycle with a large cage attached to the back.", "2. The cage is filled with a mix of small and large breed dogs.", "3. The man seems to be transporting the dogs to a special event or competition."], "CS_val": ["0.9980027079582214", "0.8950589299201965", "subjective"], "CS_val_2": ["0.9980027079582214", "0.8950589299201965", "0.03008677251636982"], "img_dir": ["img_db_CS/image_qs35_0.png", "img_db_CS/image_qs35_1.png", "img_db_CS/image_qs35_2.png", "img_db_CS/image_qs35_3.png", "img_db_CS/image_qs35_4.png"]}, {"Qnum": 36, "Question": "what hiding its head behind a bare tree?", "out": ["1. A black bear is concealing its head behind a tree in the image.", "2. The image shows a black bear hiding its head behind a bare tree."], "CS_val": ["subjective", "0.9472966194152832"], "CS_val_2": ["0.985857367515564", "0.9472966194152832"], "img_dir": ["img_db_CS/image_qs36_0.png", "img_db_CS/image_qs36_1.png", "img_db_CS/image_qs36_2.png", "img_db_CS/image_qs36_3.png", "img_db_CS/image_qs36_4.png"]}, {"Qnum": 37, "Question": "what filled with some very tasty looking food?", "out": ["1. The display case with a wide variety of donuts is the one selected from the group of images.", "2. The display case is filled with delicious-looking food."], "CS_val": ["0.4518166184425354", "subjective"], "CS_val_2": ["0.4518166184425354", "0.9990620017051697"], "img_dir": ["img_db_CS/image_qs37_0.png", "img_db_CS/image_qs37_1.png", "img_db_CS/image_qs37_2.png", "img_db_CS/image_qs37_3.png", "img_db_CS/image_qs37_4.png"]}, {"Qnum": 38, "Question": "what is sitting on a kitchen table?", "out": ["1. A teddy bear is seen sitting on a kitchen table in one of the images.", "2. The teddy bear is described as cute.", "3. The teddy bear is placed on a kitchen table.", "4. The teddy bear can be found in one of the images."], "CS_val": ["0.7155393362045288", "subjective", "subjective", "0.9991409778594971"], "CS_val_2": ["0.7155393362045288", "0.9018755555152893", "0.5802833437919617", "0.9991409778594971"], "img_dir": ["img_db_CS/image_qs38_0.png", "img_db_CS/image_qs38_1.png", "img_db_CS/image_qs38_2.png", "img_db_CS/image_qs38_3.png", "img_db_CS/image_qs38_4.png"]}, {"Qnum": 39, "Question": "what parked in front of a parking meter?", "out": ["A car is parked in front of a parking meter in a group of images."], "CS_val": ["0.9192127585411072"], "CS_val_2": ["0.9192127585411072"], "img_dir": ["img_db_CS/image_qs39_0.png", "img_db_CS/image_qs39_1.png", "img_db_CS/image_qs39_2.png", "img_db_CS/image_qs39_3.png", "img_db_CS/image_qs39_4.png"]}, {"Qnum": 40, "Question": "what are grazing on the tall tree?", "out": ["Giraffes are seen grazing on a tall tree in the group of images."], "CS_val": ["subjective"], "CS_val_2": ["0.0311025008559227"], "img_dir": ["img_db_CS/image_qs40_0.png", "img_db_CS/image_qs40_1.png", "img_db_CS/image_qs40_2.png", "img_db_CS/image_qs40_3.png", "img_db_CS/image_qs40_4.png"]}, {"Qnum": 41, "Question": "what is the man riding on the street?", "out": ["1. A man is riding a motorcycle on the street in a group of images.", "2. The man is riding a motorcycle on the street.", "3. The man is riding a motorcycle.", "4. The man is identified as a man.", "5. The man is specifically riding a motorcycle on the street."], "CS_val": ["0.04883226007223129", "0.6454022526741028", "subjective", "subjective", "0.5763601064682007"], "CS_val_2": ["0.04883226007223129", "0.6454022526741028", "0.8405439853668213", "0.9997554421424866", "0.5763601064682007"], "img_dir": ["img_db_CS/image_qs41_0.png", "img_db_CS/image_qs41_1.png", "img_db_CS/image_qs41_2.png", "img_db_CS/image_qs41_3.png", "img_db_CS/image_qs41_4.png"]}, {"Qnum": 42, "Question": "what is laying on the bed next to some pillows?", "out": ["A cat is lying on a bed next to pillows in a group of images."], "CS_val": ["0.89310622215271"], "CS_val_2": ["0.89310622215271"], "img_dir": ["img_db_CS/image_qs42_0.png", "img_db_CS/image_qs42_1.png", "img_db_CS/image_qs42_2.png", "img_db_CS/image_qs42_3.png", "img_db_CS/image_qs42_4.png"]}, {"Qnum": 43, "Question": "what is the young woman eating?", "out": ["1. A group of images is provided. ", "2. A young woman is seen consuming a hot dog."], "CS_val": ["subjective", "0.9885483980178833"], "CS_val_2": ["0.017092935740947723", "0.9885483980178833"], "img_dir": ["img_db_CS/image_qs43_0.png", "img_db_CS/image_qs43_1.png", "img_db_CS/image_qs43_2.png", "img_db_CS/image_qs43_3.png", "img_db_CS/image_qs43_4.png"]}, {"Qnum": 44, "Question": "what topped with the laptop and a monitor?", "out": ["1. A group of images is being analyzed.", "2. The laptop and monitor are situated on a wooden desk."], "CS_val": ["0.03109198994934559", "0.9682135581970215"], "CS_val_2": ["0.03109198994934559", "0.9682135581970215"], "img_dir": ["img_db_CS/image_qs44_0.png", "img_db_CS/image_qs44_1.png", "img_db_CS/image_qs44_2.png", "img_db_CS/image_qs44_3.png", "img_db_CS/image_qs44_4.png"]}, {"Qnum": 45, "Question": "what are parked next to each other on some tracks?", "out": ["1. Two red sports cars are parked next to each other on tracks in a group of images.", "2. The red sports cars are parked next to each other on tracks.", "3. The red sports cars are parked next to each other.", "4. The red sports cars are parked on tracks."], "CS_val": ["0.0605052188038826", "subjective", "subjective", "subjective"], "CS_val_2": ["0.0605052188038826", "0.03746693953871727", "0.9997079968452454", "0.03828500956296921"], "img_dir": ["img_db_CS/image_qs45_0.png", "img_db_CS/image_qs45_1.png", "img_db_CS/image_qs45_2.png", "img_db_CS/image_qs45_3.png", "img_db_CS/image_qs45_4.png"]}, {"Qnum": 46, "Question": "what are on display in a store?", "out": ["1. Several items on display in a store, including computer mice, video game consoles, books, and Nintendo Wii gaming systems.", "2. Computer mice on display.", "3. Video game consoles on display.", "4. Table with a variety of books on display.", "5. Nintendo Wii gaming systems on display.", "6. Room with a variety of items on display, including a suitcase, picture of the Eiffel Tower, and collection of stuffed animals.", "7. Suitcase on display.", "8. Picture of the Eiffel Tower on display.", "9. Collection of stuffed animals on display.", "10. Engaging and interactive atmosphere in each scene.", "11. People browsing and discussing different options available."], "CS_val": ["0.5901396870613098", "0.9926053285598755", "0.9977165460586548", "0.909636914730072", "0.8953042030334473", "0.7981606721878052", "0.8738906383514404", "0.8931022882461548", "0.0030877171084284782", "0.7592848539352417", "0.7776670455932617"], "CS_val_2": ["0.5901396870613098", "0.9926053285598755", "0.9977165460586548", "subjective", "subjective", "0.7981606721878052", "0.8738906383514404", "0.8931022882461548", "0.0030877171084284782", "0.7592848539352417", "0.7776670455932617"], "img_dir": ["img_db_CS/image_qs46_0.png", "img_db_CS/image_qs46_1.png", "img_db_CS/image_qs46_2.png", "img_db_CS/image_qs46_3.png", "img_db_CS/image_qs46_4.png"]}, {"Qnum": 47, "Question": "what is the woman in a blue shirt holding?", "out": ["1. A group of images is being discussed.", "2. A woman wearing a blue shirt is holding a blue frisbee."], "CS_val": ["0.2577971816062927", "subjective"], "CS_val_2": ["0.2577971816062927", "0.7397644519805908"], "img_dir": ["img_db_CS/image_qs47_0.png", "img_db_CS/image_qs47_1.png", "img_db_CS/image_qs47_2.png", "img_db_CS/image_qs47_3.png", "img_db_CS/image_qs47_4.png"]}, {"Qnum": 48, "Question": "what is the color of the brush?", "out": ["The brush in the group of images is white."], "CS_val": ["0.2782755196094513"], "CS_val_2": ["0.2782755196094513"], "img_dir": ["img_db_CS/image_qs48_0.png", "img_db_CS/image_qs48_1.png", "img_db_CS/image_qs48_2.png", "img_db_CS/image_qs48_3.png", "img_db_CS/image_qs48_4.png"]}, {"Qnum": 49, "Question": "what is picking up passengers along the road?", "out": ["Summary: The blue truck is seen in a group of images picking up passengers on the road."], "CS_val": ["0.0008191956439986825"], "CS_val_2": ["subjective"], "img_dir": ["img_db_CS/image_qs49_0.png", "img_db_CS/image_qs49_1.png", "img_db_CS/image_qs49_2.png", "img_db_CS/image_qs49_3.png", "img_db_CS/image_qs49_4.png"]}, {"Qnum": 50, "Question": "what are next to the open bench?", "out": ["1. A bench is beside a brick pathway in one of the images.", "2. A bench is located next to a brick pathway in one of the images.", "3. In one of the images, a bench is positioned next to a brick pathway."], "CS_val": ["0.1793326586484909", "0.06390487402677536", "subjective"], "CS_val_2": ["0.1793326586484909", "0.06390487402677536", "0.4000703692436218"], "img_dir": ["img_db_CS/image_qs50_0.png", "img_db_CS/image_qs50_1.png", "img_db_CS/image_qs50_2.png", "img_db_CS/image_qs50_3.png", "img_db_CS/image_qs50_4.png"]}, {"Qnum": 51, "Question": "what is the child holding up?", "out": ["The child in the group of images is holding a yellow flower."], "CS_val": ["0.30445143580436707"], "CS_val_2": ["0.30445143580436707"], "img_dir": ["img_db_CS/image_qs51_0.png", "img_db_CS/image_qs51_1.png", "img_db_CS/image_qs51_2.png", "img_db_CS/image_qs51_3.png", "img_db_CS/image_qs51_4.png"]}, {"Qnum": 52, "Question": "what are the bride and groom cutting?", "out": ["1. The bride and groom are shown cutting a cake in a group of images.", "2. The bride and groom are cutting a cake together.", "3. The bride and groom are participating in cake-cutting together."], "CS_val": ["0.02445915900170803", "0.9688071012496948", "0.9858309626579285"], "CS_val_2": ["0.02445915900170803", "0.9688071012496948", "0.9858309626579285"], "img_dir": ["img_db_CS/image_qs52_0.png", "img_db_CS/image_qs52_1.png", "img_db_CS/image_qs52_2.png", "img_db_CS/image_qs52_3.png", "img_db_CS/image_qs52_4.png"]}, {"Qnum": 53, "Question": "what is the color of the sauce?", "out": ["1. The sauce in the group of images is red."], "CS_val": ["0.9051789045333862"], "CS_val_2": ["0.9051789045333862"], "img_dir": ["img_db_CS/image_qs53_0.png", "img_db_CS/image_qs53_1.png", "img_db_CS/image_qs53_2.png", "img_db_CS/image_qs53_3.png", "img_db_CS/image_qs53_4.png"]}, {"Qnum": 54, "Question": "the man riding what down a snow covered slope?", "out": ["1. A man is snowboarding down a snow-covered slope in a group of images. ", "2. The man is snowboarding down a snow-covered slope. ", "3. The man is snowboarding. ", "4. The man is riding down a snow-covered slope."], "CS_val": ["0.47126683592796326", "0.974755585193634", "0.9564427137374878", "subjective"], "CS_val_2": ["0.47126683592796326", "0.974755585193634", "0.9564427137374878", "0.9897051453590393"], "img_dir": ["img_db_CS/image_qs54_0.png", "img_db_CS/image_qs54_1.png", "img_db_CS/image_qs54_2.png", "img_db_CS/image_qs54_3.png", "img_db_CS/image_qs54_4.png"]}, {"Qnum": 55, "Question": "where is the woman with a newspaper sitting?", "out": ["1. A woman in the group of images is sitting on a bench with a newspaper.", "2. She is seated on a bench.", "3. The woman is holding a newspaper.", "4. The woman is part of a group of images."], "CS_val": ["0.00019667371816467494", "subjective", "subjective", "subjective"], "CS_val_2": ["0.00019667371816467494", "0.018393222242593765", "0.09027625620365143", "0.24665865302085876"], "img_dir": ["img_db_CS/image_qs55_0.png", "img_db_CS/image_qs55_1.png", "img_db_CS/image_qs55_2.png", "img_db_CS/image_qs55_3.png", "img_db_CS/image_qs55_4.png"]}, {"Qnum": 56, "Question": "what is being loaded for a trip?", "out": ["1. A large truck is transporting a boat across a bridge in the images.", "2. A group of people with luggage, such as suitcases and handbags, are walking through a building.", "3. The images indicate that the people are either starting or ending a trip.", "4. The luggage is left waiting to be picked up or moved to another location."], "CS_val": ["0.030173171311616898", "0.9419286847114563", "subjective", "subjective"], "CS_val_2": ["0.030173171311616898", "0.9419286847114563", "0.8128119111061096", "0.6259099841117859"], "img_dir": ["img_db_CS/image_qs56_0.png", "img_db_CS/image_qs56_1.png", "img_db_CS/image_qs56_2.png", "img_db_CS/image_qs56_3.png", "img_db_CS/image_qs56_4.png"]}, {"Qnum": 57, "Question": "what is yellow and white?", "out": ["1. Yellow and white flowers are in a vase on the dining table in a group of images.", "2. Yellow and white flowers are specifically in the vase on the dining table.", "3. Yellow and white flowers are in the vase.", "4. Yellow and white flowers are on the dining table."], "CS_val": ["0.43584221601486206", "0.9392960667610168", "subjective", "subjective"], "CS_val_2": ["0.43584221601486206", "0.9392960667610168", "0.9999127388000488", "0.9778207540512085"], "img_dir": ["img_db_CS/image_qs57_0.png", "img_db_CS/image_qs57_1.png", "img_db_CS/image_qs57_2.png", "img_db_CS/image_qs57_3.png", "img_db_CS/image_qs57_4.png"]}, {"Qnum": 58, "Question": "what is the man riding through a crowded intersection?", "out": ["1. A man is riding a horse through a crowded intersection in a group of images.", "2. The man is moving gracefully through the crowd while riding the horse.", "3. The well-trained horse looks comfortable in the busy environment of the crowded intersection."], "CS_val": ["0.19888056814670563", "subjective", "0.7708583474159241"], "CS_val_2": ["0.19888056814670563", "0.6480918526649475", "subjective"], "img_dir": ["img_db_CS/image_qs58_0.png", "img_db_CS/image_qs58_1.png", "img_db_CS/image_qs58_2.png", "img_db_CS/image_qs58_3.png", "img_db_CS/image_qs58_4.png"]}, {"Qnum": 59, "Question": "what near lounge chairs at the beach?", "out": ["- Image 3 in the group shows a lounge chair at the beach."], "CS_val": ["0.9944124817848206"], "CS_val_2": ["0.9944124817848206"], "img_dir": ["img_db_CS/image_qs59_0.png", "img_db_CS/image_qs59_1.png", "img_db_CS/image_qs59_2.png", "img_db_CS/image_qs59_3.png", "img_db_CS/image_qs59_4.png"]}, {"Qnum": 60, "Question": "what is the smiling group of dressed up people are eating?", "out": ["1. A group of images is provided for analysis.", "2. The group of people, who are smiling and dressed up, are currently enjoying cake."], "CS_val": ["0.6712070107460022", "subjective"], "CS_val_2": ["0.6712070107460022", "0.0002474186767358333"], "img_dir": ["img_db_CS/image_qs60_0.png", "img_db_CS/image_qs60_1.png", "img_db_CS/image_qs60_2.png", "img_db_CS/image_qs60_3.png", "img_db_CS/image_qs60_4.png"]}, {"Qnum": 61, "Question": "what does the woman hold up in front of her face?", "out": ["1. The woman in the images is seen holding a cell phone up in front of her face."], "CS_val": ["0.6595210433006287"], "CS_val_2": ["0.6595210433006287"], "img_dir": ["img_db_CS/image_qs61_0.png", "img_db_CS/image_qs61_1.png", "img_db_CS/image_qs61_2.png", "img_db_CS/image_qs61_3.png", "img_db_CS/image_qs61_4.png"]}, {"Qnum": 62, "Question": "what is sitting on the tree branch spreading its tail-feathers?", "out": ["1. The red cardinal is perched on a tree branch in image3, spreading its tail-feathers.", "2. The bird in image3 is sitting on a tree branch.", "3. The bird in image3 is spreading its tail-feathers.", "4. The bird in image3 is identified as a red cardinal."], "CS_val": ["0.47122594714164734", "subjective", "subjective", "subjective"], "CS_val_2": ["0.47122594714164734", "0.754841685295105", "0.9238588809967041", "0.9965648055076599"], "img_dir": ["img_db_CS/image_qs62_0.png", "img_db_CS/image_qs62_1.png", "img_db_CS/image_qs62_2.png", "img_db_CS/image_qs62_3.png", "img_db_CS/image_qs62_4.png"]}, {"Qnum": 63, "Question": "what is the person in a hat riding?", "out": ["The person wearing a hat is skateboarding in the group of images."], "CS_val": ["0.20131458342075348"], "CS_val_2": ["0.20131458342075348"], "img_dir": ["img_db_CS/image_qs63_0.png", "img_db_CS/image_qs63_1.png", "img_db_CS/image_qs63_2.png", "img_db_CS/image_qs63_3.png", "img_db_CS/image_qs63_4.png"]}, {"Qnum": 64, "Question": "what is taking off into the sky with its landing gear still extended?", "out": ["1. A large airplane is depicted in a group of images, taking off into the sky with its landing gear still extended.", "2. The extended landing gear suggests that the airplane is in the initial phase of ascending from the runway.", "3. The presence of the landing gear indicates that the aircraft has recently landed and is now starting its journey back into the sky."], "CS_val": ["0.322935551404953", "0.5491321086883545", "subjective"], "CS_val_2": ["0.322935551404953", "0.5491321086883545", "0.7540984749794006"], "img_dir": ["img_db_CS/image_qs64_0.png", "img_db_CS/image_qs64_1.png", "img_db_CS/image_qs64_2.png", "img_db_CS/image_qs64_3.png", "img_db_CS/image_qs64_4.png"]}, {"Qnum": 65, "Question": "what are sleeping on the bed with a red bedspread?", "out": ["1. An image shows a baby sleeping on a bed with a red bedspread.", "2. The baby is peacefully sleeping on the bed with a red bedspread.", "3. The bedspread underneath the baby is red.", "4. The infant appears to be soundly sleeping on the bed.", "5. The sleeping baby is laying on a bed with a red bedspread."], "CS_val": ["0.1919262856245041", "subjective", "subjective", "subjective", "0.04466509819030762"], "CS_val_2": ["0.1919262856245041", "subjective", "0.040967244654893875", "0.9990887641906738", "0.04466509819030762"], "img_dir": ["img_db_CS/image_qs65_0.png", "img_db_CS/image_qs65_1.png", "img_db_CS/image_qs65_2.png", "img_db_CS/image_qs65_3.png", "img_db_CS/image_qs65_4.png"]}, {"Qnum": 66, "Question": "where does the woman take a photo of herself?", "out": ["The woman in the group of images takes a selfie in image1."], "CS_val": ["0.9956346154212952"], "CS_val_2": ["0.9956346154212952"], "img_dir": ["img_db_CS/image_qs66_0.png", "img_db_CS/image_qs66_1.png", "img_db_CS/image_qs66_2.png", "img_db_CS/image_qs66_3.png", "img_db_CS/image_qs66_4.png"]}]