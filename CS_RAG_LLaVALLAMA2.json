[{"Qnum": 0, "Question": "what are sitting on the counter in different stages of cutting with a knife?", "out": ["1. Image 2 shows a person cutting an apple on a wooden cutting board.", "2. The person is using a knife to slice the apple into pieces on the cutting board.", "3. The apple is positioned on the left side of the cutting board, while the person is on the right side cutting the fruit with a knife."], "CS_val": ["0.00027785738348029554", "0.00013558968203142285", "subjective"], "CS_val_2": ["0.00027785738348029554", "0.00013558968203142285", "0.03229726478457451"], "img_dir": ["img_db_CS/image_qs0_0.png", "img_db_CS/image_qs0_1.png", "img_db_CS/image_qs0_2.png", "img_db_CS/image_qs0_3.png", "img_db_CS/image_qs0_4.png"]}, {"Qnum": 1, "Question": "where does the person sit next to a top with a hat on?", "out": ["1. The person in the image is seated on a bench.", "2. The person is dressed in a yellow dress and wearing a hat."], "CS_val": ["0.00046213396126404405", "7.419876055791974e-05"], "CS_val_2": ["0.00046213396126404405", "7.419876055791974e-05"], "img_dir": ["img_db_CS/image_qs1_0.png", "img_db_CS/image_qs1_1.png", "img_db_CS/image_qs1_2.png", "img_db_CS/image_qs1_3.png", "img_db_CS/image_qs1_4.png"]}, {"Qnum": 2, "Question": "what are standing in tall dry grass look at the tourists?", "out": ["1. A giraffe is present in a group of images, standing in tall dry grass.", "2. The giraffe is looking at tourists."], "CS_val": ["1.58940765686566e-05", "subjective"], "CS_val_2": ["1.58940765686566e-05", "0.0010889667319133878"], "img_dir": ["img_db_CS/image_qs2_0.png", "img_db_CS/image_qs2_1.png", "img_db_CS/image_qs2_2.png", "img_db_CS/image_qs2_3.png", "img_db_CS/image_qs2_4.png"]}, {"Qnum": 3, "Question": "the man carrying what runs into the ocean?", "out": ["1. Images in a group are being analyzed.", "2. A man is seen entering the ocean while carrying a surfboard."], "CS_val": ["0.4086929261684418", "subjective"], "CS_val_2": ["0.4086929261684418", "0.0007862774073146284"], "img_dir": ["img_db_CS/image_qs3_0.png", "img_db_CS/image_qs3_1.png", "img_db_CS/image_qs3_2.png", "img_db_CS/image_qs3_3.png", "img_db_CS/image_qs3_4.png"]}, {"Qnum": 4, "Question": "what is playing with the large chunk of ice?", "out": ["1. A polar bear is seen playing with a large chunk of ice in a group of images.", "2. The polar bear is situated on a snow-covered ground near the ice.", "3. The ice is being treated as a toy or sports ball by the bear.", "4. The bear's playful and curious nature is evident as it interacts with the objects around it in the scene."], "CS_val": ["subjective", "0.011550034396350384", "subjective", "2.2756918042432517e-05"], "CS_val_2": ["9.25311633181991e-06", "0.011550034396350384", "0.0026174692902714014", "2.2756918042432517e-05"], "img_dir": ["img_db_CS/image_qs4_0.png", "img_db_CS/image_qs4_1.png", "img_db_CS/image_qs4_2.png", "img_db_CS/image_qs4_3.png", "img_db_CS/image_qs4_4.png"]}, {"Qnum": 5, "Question": "what covered in white linen in a bedroom with a dresser?", "out": ["1. A bedroom is present among the group of images.", "2. The bed in the bedroom is adorned with white linen.", "3. The bedroom also includes a dresser."], "CS_val": ["7.487000402761623e-05", "0.002079644240438938", "subjective"], "CS_val_2": ["7.487000402761623e-05", "0.002079644240438938", "9.59870230872184e-05"], "img_dir": ["img_db_CS/image_qs5_0.png", "img_db_CS/image_qs5_1.png", "img_db_CS/image_qs5_2.png", "img_db_CS/image_qs5_3.png", "img_db_CS/image_qs5_4.png"]}, {"Qnum": 6, "Question": "what is the color of the airplane?", "out": ["The airplane in the group of images is white and red."], "CS_val": ["0.08316825330257416"], "CS_val_2": ["0.08316825330257416"], "img_dir": ["img_db_CS/image_qs6_0.png", "img_db_CS/image_qs6_1.png", "img_db_CS/image_qs6_2.png", "img_db_CS/image_qs6_3.png", "img_db_CS/image_qs6_4.png"]}, {"Qnum": 7, "Question": "what is parked on the side of the grass?", "out": ["A red pickup truck is parked on the grass in the group of images."], "CS_val": ["1.1555333003343549e-05"], "CS_val_2": ["1.1555333003343549e-05"], "img_dir": ["img_db_CS/image_qs7_0.png", "img_db_CS/image_qs7_1.png", "img_db_CS/image_qs7_2.png", "img_db_CS/image_qs7_3.png", "img_db_CS/image_qs7_4.png"]}, {"Qnum": 8, "Question": "what are sitting on top of wood poles?", "out": ["1. A black bird is perched on a metal pipe in a group of images.", "2. The bird is perched on the pipe.", "3. The bird is looking around.", "4. The bird is observing its surroundings."], "CS_val": ["0.013782636262476444", "0.9552707672119141", "subjective", "subjective"], "CS_val_2": ["0.013782636262476444", "0.9552707672119141", "0.8994945883750916", "0.9963376522064209"], "img_dir": ["img_db_CS/image_qs8_0.png", "img_db_CS/image_qs8_1.png", "img_db_CS/image_qs8_2.png", "img_db_CS/image_qs8_3.png", "img_db_CS/image_qs8_4.png"]}, {"Qnum": 9, "Question": "what is the color of the kitten?", "out": ["The kitten in the group of images is brown and white."], "CS_val": ["7.465497765224427e-05"], "CS_val_2": ["7.465497765224427e-05"], "img_dir": ["img_db_CS/image_qs9_0.png", "img_db_CS/image_qs9_1.png", "img_db_CS/image_qs9_2.png", "img_db_CS/image_qs9_3.png", "img_db_CS/image_qs9_4.png"]}, {"Qnum": 10, "Question": "what is the color of the plate?", "out": ["The plates in the group of images are white."], "CS_val": ["0.08562949299812317"], "CS_val_2": ["0.08562949299812317"], "img_dir": ["img_db_CS/image_qs10_0.png", "img_db_CS/image_qs10_1.png", "img_db_CS/image_qs10_2.png", "img_db_CS/image_qs10_3.png", "img_db_CS/image_qs10_4.png"]}, {"Qnum": 11, "Question": "what are sitting on the wooden perch over grass and bushes?", "out": ["1. Image group includes a wooden bench on a wooden perch surrounded by grass and bushes.", "2. The wooden bench is positioned above grass and bushes on a wooden perch.", "3. Wooden bench rests on a wooden perch above grass and bushes."], "CS_val": ["0.006852965801954269", "0.01987275667488575", "subjective"], "CS_val_2": ["0.006852965801954269", "0.01987275667488575", "0.647485077381134"], "img_dir": ["img_db_CS/image_qs11_0.png", "img_db_CS/image_qs11_1.png", "img_db_CS/image_qs11_2.png", "img_db_CS/image_qs11_3.png", "img_db_CS/image_qs11_4.png"]}, {"Qnum": 12, "Question": "what stands in the rocky area , larger rocks behind him?", "out": ["1. A brown bear is depicted standing in a rocky area in the image.", "2. Larger rocks are seen behind the brown bear in the image."], "CS_val": ["4.4569365854840726e-05", "subjective"], "CS_val_2": ["4.4569365854840726e-05", "0.03213959559798241"], "img_dir": ["img_db_CS/image_qs12_0.png", "img_db_CS/image_qs12_1.png", "img_db_CS/image_qs12_2.png", "img_db_CS/image_qs12_3.png", "img_db_CS/image_qs12_4.png"]}, {"Qnum": 13, "Question": "what are rubbing their heads and necks together?", "out": ["The dogs in the group of images are engaging in behavior where they are rubbing their heads and necks together."], "CS_val": ["6.915393896633759e-05"], "CS_val_2": ["6.915393896633759e-05"], "img_dir": ["img_db_CS/image_qs13_0.png", "img_db_CS/image_qs13_1.png", "img_db_CS/image_qs13_2.png", "img_db_CS/image_qs13_3.png", "img_db_CS/image_qs13_4.png"]}, {"Qnum": 14, "Question": "what is the color of the freezer?", "out": ["1. The freezer in the group of images is colored in black and white.", "2. The freezer is primarily black and white in color."], "CS_val": ["0.014537847600877285", "subjective"], "CS_val_2": ["0.014537847600877285", "0.007485677488148212"], "img_dir": ["img_db_CS/image_qs14_0.png", "img_db_CS/image_qs14_1.png", "img_db_CS/image_qs14_2.png", "img_db_CS/image_qs14_3.png", "img_db_CS/image_qs14_4.png"]}, {"Qnum": 15, "Question": "what is laying next to a book shelf filled with books?", "out": ["1. A stuffed animal is next to a bookshelf filled with books in a group of images.", "2. The stuffed animal is lying near a bookshelf that is filled with books.", "3. The bookshelf is completely filled with books."], "CS_val": ["7.506000838475302e-05", "subjective", "subjective"], "CS_val_2": ["7.506000838475302e-05", "0.004673302173614502", "0.004987380467355251"], "img_dir": ["img_db_CS/image_qs15_0.png", "img_db_CS/image_qs15_1.png", "img_db_CS/image_qs15_2.png", "img_db_CS/image_qs15_3.png", "img_db_CS/image_qs15_4.png"]}, {"Qnum": 16, "Question": "what are standing in the grassy field?", "out": ["1. Two white sheep are in the group of images.", "2. The white sheep are standing in a grassy field.", "3. A black and white cow is in the group of images.", "4. The cow is standing in a grassy field.", "5. A large brown horse is in the group of images.", "6. The horse is standing in a grassy field."], "CS_val": ["7.040590389806312e-06", "0.00011797554179793224", "8.034241909626871e-05", "2.7781015887740068e-05", "2.356932782276999e-06", "9.287851571571082e-05"], "CS_val_2": ["7.040590389806312e-06", "0.00011797554179793224", "8.034241909626871e-05", "2.7781015887740068e-05", "2.356932782276999e-06", "9.287851571571082e-05"], "img_dir": ["img_db_CS/image_qs16_0.png", "img_db_CS/image_qs16_1.png", "img_db_CS/image_qs16_2.png", "img_db_CS/image_qs16_3.png", "img_db_CS/image_qs16_4.png"]}, {"Qnum": 17, "Question": "what are flying through the sky?", "out": ["1. Two objects can be seen flying through the sky in the group of images.", "2. The objects flying through the sky consist of an airplane and a bird."], "CS_val": ["0.003748555202037096", "subjective"], "CS_val_2": ["0.003748555202037096", "0.9664862751960754"], "img_dir": ["img_db_CS/image_qs17_0.png", "img_db_CS/image_qs17_1.png", "img_db_CS/image_qs17_2.png", "img_db_CS/image_qs17_3.png", "img_db_CS/image_qs17_4.png"]}, {"Qnum": 18, "Question": "what filled with the variety of food?", "out": ["1. Image1 in the group of images is filled with a variety of food.", "2. The image shows a tray with a bagel, eggs, and fruit.", "3. The bagel is cut in half to show its contents.", "4. The tray is placed on a dining table with a green polka dot tablecloth."], "CS_val": ["subjective", "5.943198993918486e-05", "0.00014223004109226167", "0.00014830453437753022"], "CS_val_2": ["0.02353292889893055", "5.943198993918486e-05", "0.00014223004109226167", "0.00014830453437753022"], "img_dir": ["img_db_CS/image_qs18_0.png", "img_db_CS/image_qs18_1.png", "img_db_CS/image_qs18_2.png", "img_db_CS/image_qs18_3.png", "img_db_CS/image_qs18_4.png"]}, {"Qnum": 19, "Question": "people standing on the street holding what?", "out": ["1. People standing on the street holding umbrellas.", "2. Protecting themselves from the rain.", "3. Wet street with visible reflections.", "4. Mix of colorful and plain umbrellas.", "5. People looking up at the sky."], "CS_val": ["0.0008664320921525359", "0.016758520156145096", "0.01048927940428257", "0.0016996623016893864", "subjective"], "CS_val_2": ["0.0008664320921525359", "0.016758520156145096", "0.01048927940428257", "0.0016996623016893864", "0.0003798164543695748"], "img_dir": ["img_db_CS/image_qs19_0.png", "img_db_CS/image_qs19_1.png", "img_db_CS/image_qs19_2.png", "img_db_CS/image_qs19_3.png", "img_db_CS/image_qs19_4.png"]}, {"Qnum": 20, "Question": "what is the man in the black leather coat holding?", "out": ["1. A man in a black leather coat is seen holding a handbag in a group of images.", "2. The man in the group is wearing a black leather coat.", "3. The man in the group is seen holding a handbag."], "CS_val": ["2.1613963326672092e-05", "0.0018935005646198988", "subjective"], "CS_val_2": ["2.1613963326672092e-05", "0.0018935005646198988", "0.00020536845840979367"], "img_dir": ["img_db_CS/image_qs20_0.png", "img_db_CS/image_qs20_1.png", "img_db_CS/image_qs20_2.png", "img_db_CS/image_qs20_3.png", "img_db_CS/image_qs20_4.png"]}, {"Qnum": 21, "Question": "what does the view of a street at night show?", "out": ["1. A lively urban environment is depicted in the images of a street at night.", "2. Streetlights illuminate the street in the pictures.", "3. People are seen walking around, with some carrying handbags.", "4. Cars, parking meters, and traffic lights highlight the urban setting.", "5. The presence of pedestrians adds to the energy and activity of the busy street.", "6. The images effectively convey the vibrant atmosphere of a city at night."], "CS_val": ["0.0006450453074648976", "0.0015724555123597383", "0.00010110169387189671", "8.141801663441584e-05", "0.005065842065960169", "subjective"], "CS_val_2": ["0.0006450453074648976", "0.0015724555123597383", "0.00010110169387189671", "8.141801663441584e-05", "0.005065842065960169", "0.0004891089629381895"], "img_dir": ["img_db_CS/image_qs21_0.png", "img_db_CS/image_qs21_1.png", "img_db_CS/image_qs21_2.png", "img_db_CS/image_qs21_3.png", "img_db_CS/image_qs21_4.png"]}, {"Qnum": 22, "Question": "what is lying on the concrete surface?", "out": ["1. In the group of images, there is a wooden bench on concrete.", "2. The wooden bench is on concrete."], "CS_val": ["0.024530570954084396", "0.10101030766963959"], "CS_val_2": ["0.024530570954084396", "0.10101030766963959"], "img_dir": ["img_db_CS/image_qs22_0.png", "img_db_CS/image_qs22_1.png", "img_db_CS/image_qs22_2.png", "img_db_CS/image_qs22_3.png", "img_db_CS/image_qs22_4.png"]}, {"Qnum": 23, "Question": "what is the color of the jacket?", "out": ["The jacket in the group of images is black and white."], "CS_val": ["0.017375851050019264"], "CS_val_2": ["0.017375851050019264"], "img_dir": ["img_db_CS/image_qs23_0.png", "img_db_CS/image_qs23_1.png", "img_db_CS/image_qs23_2.png", "img_db_CS/image_qs23_3.png", "img_db_CS/image_qs23_4.png"]}, {"Qnum": 24, "Question": "what is going down the street?", "out": ["1. A group of motorcyclists are riding down the street in a group of images.", "2. The motorcyclists are riding in a single file line.", "3. Safety is a priority as the motorcyclists are wearing helmets.", "4. The street is crowded with other vehicles."], "CS_val": ["3.224982719984837e-05", "subjective", "0.8958248496055603", "6.546982331201434e-05"], "CS_val_2": ["3.224982719984837e-05", "0.008240468800067902", "0.8958248496055603", "6.546982331201434e-05"], "img_dir": ["img_db_CS/image_qs24_0.png", "img_db_CS/image_qs24_1.png", "img_db_CS/image_qs24_2.png", "img_db_CS/image_qs24_3.png", "img_db_CS/image_qs24_4.png"]}, {"Qnum": 25, "Question": "what filled with tooth brushes on top of a counter?", "out": ["1. The group of images contains a scene.", "2. The scene depicted in the image is of a toothbrush holder filled with toothbrushes on a counter."], "CS_val": ["0.8200207352638245", "4.3751100747613236e-05"], "CS_val_2": ["0.8200207352638245", "4.3751100747613236e-05"], "img_dir": ["img_db_CS/image_qs25_0.png", "img_db_CS/image_qs25_1.png", "img_db_CS/image_qs25_2.png", "img_db_CS/image_qs25_3.png", "img_db_CS/image_qs25_4.png"]}, {"Qnum": 26, "Question": "what does the giraffe lick at the zoo?", "out": ["1. The giraffe in <image3> at the zoo was observed licking the ground."], "CS_val": ["subjective"], "CS_val_2": ["0.00020787990069948137"], "img_dir": ["img_db_CS/image_qs26_0.png", "img_db_CS/image_qs26_1.png", "img_db_CS/image_qs26_2.png", "img_db_CS/image_qs26_3.png", "img_db_CS/image_qs26_4.png"]}, {"Qnum": 27, "Question": "what are face to face along side a roadway?", "out": ["1. A man is riding a motorcycle on a highway in a group of images.", "2. The man on the motorcycle is being followed by a car.", "3. The motorcycle and car are in a face-to-face position on the roadway."], "CS_val": ["9.445730393053964e-05", "0.002777807181701064", "subjective"], "CS_val_2": ["9.445730393053964e-05", "0.002777807181701064", "subjective"], "img_dir": ["img_db_CS/image_qs27_0.png", "img_db_CS/image_qs27_1.png", "img_db_CS/image_qs27_2.png", "img_db_CS/image_qs27_3.png", "img_db_CS/image_qs27_4.png"]}, {"Qnum": 28, "Question": "where does the dog sniff some food?", "out": ["1. The dog in <image1> is shown sniffing food. ", "2. The dog is in a kitchen, looking into an open refrigerator with curiosity."], "CS_val": ["0.0008494560024701059", "subjective"], "CS_val_2": ["0.0008494560024701059", "0.00302937556989491"], "img_dir": ["img_db_CS/image_qs28_0.png", "img_db_CS/image_qs28_1.png", "img_db_CS/image_qs28_2.png", "img_db_CS/image_qs28_3.png", "img_db_CS/image_qs28_4.png"]}, {"Qnum": 29, "Question": "the woman with a hat , tie and striped halter smoking what?", "out": ["A woman in a group of images is identified by her distinctive attire and is seen smoking a cigarette."], "CS_val": ["subjective"], "CS_val_2": ["4.063791857333854e-05"], "img_dir": ["img_db_CS/image_qs29_0.png", "img_db_CS/image_qs29_1.png", "img_db_CS/image_qs29_2.png", "img_db_CS/image_qs29_3.png", "img_db_CS/image_qs29_4.png"]}, {"Qnum": 30, "Question": "what is covered with rust?", "out": ["1. Old blue and red truck in group of images covered with rust.", "2. Old blue and red truck is covered in rust.", "3. The truck is old and rusted.", "4. The truck is blue and red.", "5. The truck is covered in rust."], "CS_val": ["7.758936408208683e-05", "0.004108760505914688", "subjective", "subjective", "subjective"], "CS_val_2": ["7.758936408208683e-05", "0.004108760505914688", "0.025877930223941803", "0.0005831395392306149", "0.05686914175748825"], "img_dir": ["img_db_CS/image_qs30_0.png", "img_db_CS/image_qs30_1.png", "img_db_CS/image_qs30_2.png", "img_db_CS/image_qs30_3.png", "img_db_CS/image_qs30_4.png"]}, {"Qnum": 31, "Question": "what is the color of the barns?", "out": ["1. The images in the group all feature red barns.", "2. Barns are uniformly colored red."], "CS_val": ["1.3715948625758756e-05", "subjective"], "CS_val_2": ["1.3715948625758756e-05", "0.0011359580093994737"], "img_dir": ["img_db_CS/image_qs31_0.png", "img_db_CS/image_qs31_1.png", "img_db_CS/image_qs31_2.png", "img_db_CS/image_qs31_3.png", "img_db_CS/image_qs31_4.png"]}, {"Qnum": 32, "Question": "what sits among floral decorations?", "out": ["1. There is a wooden bookshelf in a group of images.", "2. The wooden bookshelf is decorated with a wheat plant or straw flower among the floral decorations."], "CS_val": ["4.827473821933381e-05", "subjective"], "CS_val_2": ["4.827473821933381e-05", "0.0006653905147686601"], "img_dir": ["img_db_CS/image_qs32_0.png", "img_db_CS/image_qs32_1.png", "img_db_CS/image_qs32_2.png", "img_db_CS/image_qs32_3.png", "img_db_CS/image_qs32_4.png"]}, {"Qnum": 33, "Question": "what is laying on top of a large rock?", "out": ["A brown bear is resting on a large rock among a group of images."], "CS_val": ["6.450365162891103e-06"], "CS_val_2": ["6.450365162891103e-06"], "img_dir": ["img_db_CS/image_qs33_0.png", "img_db_CS/image_qs33_1.png", "img_db_CS/image_qs33_2.png", "img_db_CS/image_qs33_3.png", "img_db_CS/image_qs33_4.png"]}, {"Qnum": 34, "Question": "what lined up on tarmac with landing gear in sunny day?", "out": ["1. A large airplane is parked on the tarmac with its landing gear down.", "2. The weather is sunny."], "CS_val": ["0.0015175873413681984", "0.8827093839645386"], "CS_val_2": ["0.0015175873413681984", "0.8827093839645386"], "img_dir": ["img_db_CS/image_qs34_0.png", "img_db_CS/image_qs34_1.png", "img_db_CS/image_qs34_2.png", "img_db_CS/image_qs34_3.png", "img_db_CS/image_qs34_4.png"]}, {"Qnum": 35, "Question": "what is being transported in the truck down a road?", "out": ["1. A man is seen riding a motorcycle with a large cage attached to the back.", "2. The cage is filled with dogs of varying sizes.", "3. The man seems to be transporting the dogs, potentially for a competition or event."], "CS_val": ["subjective", "subjective", "0.01031124871224165"], "CS_val_2": ["0.004538257140666246", "2.471232073730789e-05", "0.01031124871224165"], "img_dir": ["img_db_CS/image_qs35_0.png", "img_db_CS/image_qs35_1.png", "img_db_CS/image_qs35_2.png", "img_db_CS/image_qs35_3.png", "img_db_CS/image_qs35_4.png"]}, {"Qnum": 36, "Question": "what hiding its head behind a bare tree?", "out": ["1. A black bear is concealing its head behind a bare tree in the image.", "2. The black bear is hiding its head behind a tree that has no leaves.", "3. The black bear is using a bare tree to hide its head."], "CS_val": ["6.83551697875373e-05", "0.0009022080339491367", "subjective"], "CS_val_2": ["6.83551697875373e-05", "0.0009022080339491367", "0.001863969606347382"], "img_dir": ["img_db_CS/image_qs36_0.png", "img_db_CS/image_qs36_1.png", "img_db_CS/image_qs36_2.png", "img_db_CS/image_qs36_3.png", "img_db_CS/image_qs36_4.png"]}, {"Qnum": 37, "Question": "what filled with some very tasty looking food?", "out": ["1. The display case in the group of images contains a wide variety of donuts.", "2. The food in the display case looks very tasty."], "CS_val": ["0.00018472466035746038", "subjective"], "CS_val_2": ["0.00018472466035746038", "0.0027670918498188257"], "img_dir": ["img_db_CS/image_qs37_0.png", "img_db_CS/image_qs37_1.png", "img_db_CS/image_qs37_2.png", "img_db_CS/image_qs37_3.png", "img_db_CS/image_qs37_4.png"]}, {"Qnum": 38, "Question": "what is sitting on a kitchen table?", "out": ["A teddy bear is seen sitting on a kitchen table in one of the images in the group."], "CS_val": ["6.0885222410433926e-06"], "CS_val_2": ["6.0885222410433926e-06"], "img_dir": ["img_db_CS/image_qs38_0.png", "img_db_CS/image_qs38_1.png", "img_db_CS/image_qs38_2.png", "img_db_CS/image_qs38_3.png", "img_db_CS/image_qs38_4.png"]}, {"Qnum": 39, "Question": "what parked in front of a parking meter?", "out": ["1. A car is parked in front of a parking meter in a group of images.", "2. The car is parked directly in front of a parking meter."], "CS_val": ["0.00023055728524923325", "0.013439384289085865"], "CS_val_2": ["0.00023055728524923325", "0.013439384289085865"], "img_dir": ["img_db_CS/image_qs39_0.png", "img_db_CS/image_qs39_1.png", "img_db_CS/image_qs39_2.png", "img_db_CS/image_qs39_3.png", "img_db_CS/image_qs39_4.png"]}, {"Qnum": 40, "Question": "what are grazing on the tall tree?", "out": ["- Giraffes are grazing on a tall tree."], "CS_val": ["9.132960258284584e-05"], "CS_val_2": ["9.132960258284584e-05"], "img_dir": ["img_db_CS/image_qs40_0.png", "img_db_CS/image_qs40_1.png", "img_db_CS/image_qs40_2.png", "img_db_CS/image_qs40_3.png", "img_db_CS/image_qs40_4.png"]}, {"Qnum": 41, "Question": "what is the man riding on the street?", "out": ["The man in the group of images is riding a motorcycle on the street."], "CS_val": ["7.825515058357269e-05"], "CS_val_2": ["7.825515058357269e-05"], "img_dir": ["img_db_CS/image_qs41_0.png", "img_db_CS/image_qs41_1.png", "img_db_CS/image_qs41_2.png", "img_db_CS/image_qs41_3.png", "img_db_CS/image_qs41_4.png"]}, {"Qnum": 42, "Question": "what is laying on the bed next to some pillows?", "out": ["1. A cat is laying on the bed with pillows nearby in a group of images. ", "2. The cat is laying next to pillows on the bed. ", "3. A cat is resting on the bed near pillows."], "CS_val": ["7.614342030137777e-05", "0.0002964171289931983", "subjective"], "CS_val_2": ["7.614342030137777e-05", "0.0002964171289931983", "0.0037518353201448917"], "img_dir": ["img_db_CS/image_qs42_0.png", "img_db_CS/image_qs42_1.png", "img_db_CS/image_qs42_2.png", "img_db_CS/image_qs42_3.png", "img_db_CS/image_qs42_4.png"]}, {"Qnum": 43, "Question": "what is the young woman eating?", "out": ["1. A young woman is featured in a group of images, and she is seen eating a hot dog.", "2. The focus of the images is on a young woman who is enjoying a hot dog."], "CS_val": ["0.00033039829577319324", "2.414374478121317e-07"], "CS_val_2": ["0.00033039829577319324", "2.414374478121317e-07"], "img_dir": ["img_db_CS/image_qs43_0.png", "img_db_CS/image_qs43_1.png", "img_db_CS/image_qs43_2.png", "img_db_CS/image_qs43_3.png", "img_db_CS/image_qs43_4.png"]}, {"Qnum": 44, "Question": "what topped with the laptop and a monitor?", "out": ["1. The laptop and the monitor are on a wooden desk in a group of images. ", "2. The laptop and monitor are on a wooden desk. ", "3. The laptop and monitor are on a wooden desk."], "CS_val": ["0.000273452460533008", "subjective", "subjective"], "CS_val_2": ["0.000273452460533008", "0.06104401499032974", "0.2527523934841156"], "img_dir": ["img_db_CS/image_qs44_0.png", "img_db_CS/image_qs44_1.png", "img_db_CS/image_qs44_2.png", "img_db_CS/image_qs44_3.png", "img_db_CS/image_qs44_4.png"]}, {"Qnum": 45, "Question": "what are parked next to each other on some tracks?", "out": ["1. Two red sports cars are parked next to each other on tracks in a group of images.", "2. The red sports cars are parked next to each other.", "3. The red sports cars are parked on tracks."], "CS_val": ["0.0003533386916387826", "0.002596446545794606", "subjective"], "CS_val_2": ["0.0003533386916387826", "0.002596446545794606", "0.0001891560386866331"], "img_dir": ["img_db_CS/image_qs45_0.png", "img_db_CS/image_qs45_1.png", "img_db_CS/image_qs45_2.png", "img_db_CS/image_qs45_3.png", "img_db_CS/image_qs45_4.png"]}, {"Qnum": 46, "Question": "what are on display in a store?", "out": ["1. A store is displaying several items in a group of images.", "2. Computer mice are among the items displayed.", "3. Video game consoles are part of the display.", "4. A table with a variety of books is also on display.", "5. Nintendo Wii gaming systems are included in the display.", "6. Various items are displayed in a room.", "7. Among the items is a suitcase.", "8. A picture of the Eiffel Tower is featured.", "9. A collection of stuffed animals is part of the display.", "10. The atmosphere in each scene is engaging and interactive.", "11. People are browsing and discussing the available options."], "CS_val": ["0.00029210353386588395", "1.1007679859176278e-05", "0.0018687022384256124", "subjective", "subjective", "subjective", "6.655924516962841e-05", "0.00025178477517329156", "subjective", "subjective", "subjective"], "CS_val_2": ["0.00029210353386588395", "1.1007679859176278e-05", "subjective", "8.284853538498282e-05", "0.0004210274782963097", "0.0024242291692644358", "6.655924516962841e-05", "0.00025178477517329156", "0.00016494901501573622", "0.5197611451148987", "9.29963935050182e-05"], "img_dir": ["img_db_CS/image_qs46_0.png", "img_db_CS/image_qs46_1.png", "img_db_CS/image_qs46_2.png", "img_db_CS/image_qs46_3.png", "img_db_CS/image_qs46_4.png"]}, {"Qnum": 47, "Question": "what is the woman in a blue shirt holding?", "out": ["1. The group of images includes multiple pictures.", "2. A woman is wearing a blue shirt and holding a blue frisbee."], "CS_val": ["subjective", "0.0014640780864283442"], "CS_val_2": ["0.9935576319694519", "0.0014640780864283442"], "img_dir": ["img_db_CS/image_qs47_0.png", "img_db_CS/image_qs47_1.png", "img_db_CS/image_qs47_2.png", "img_db_CS/image_qs47_3.png", "img_db_CS/image_qs47_4.png"]}, {"Qnum": 48, "Question": "what is the color of the brush?", "out": ["- Images in the group feature a brush that is white in color."], "CS_val": ["0.024331502616405487"], "CS_val_2": ["0.024331502616405487"], "img_dir": ["img_db_CS/image_qs48_0.png", "img_db_CS/image_qs48_1.png", "img_db_CS/image_qs48_2.png", "img_db_CS/image_qs48_3.png", "img_db_CS/image_qs48_4.png"]}, {"Qnum": 49, "Question": "what is picking up passengers along the road?", "out": ["Summary: The blue truck in the images is seen stopping to pick up passengers on the side of the road."], "CS_val": ["5.128869815962389e-05"], "CS_val_2": ["subjective"], "img_dir": ["img_db_CS/image_qs49_0.png", "img_db_CS/image_qs49_1.png", "img_db_CS/image_qs49_2.png", "img_db_CS/image_qs49_3.png", "img_db_CS/image_qs49_4.png"]}, {"Qnum": 50, "Question": "what are next to the open bench?", "out": ["One image in the group shows a bench next to a brick pathway."], "CS_val": ["0.00010899259359575808"], "CS_val_2": ["0.00010899259359575808"], "img_dir": ["img_db_CS/image_qs50_0.png", "img_db_CS/image_qs50_1.png", "img_db_CS/image_qs50_2.png", "img_db_CS/image_qs50_3.png", "img_db_CS/image_qs50_4.png"]}, {"Qnum": 51, "Question": "what is the child holding up?", "out": ["1. A child is holding a yellow flower in a group of images.", "2. The child is holding a yellow flower.", "3. The child is holding a yellow flower."], "CS_val": ["4.7178957174764946e-05", "subjective", "subjective"], "CS_val_2": ["4.7178957174764946e-05", "0.0025802585296332836", "0.0033684256486594677"], "img_dir": ["img_db_CS/image_qs51_0.png", "img_db_CS/image_qs51_1.png", "img_db_CS/image_qs51_2.png", "img_db_CS/image_qs51_3.png", "img_db_CS/image_qs51_4.png"]}, {"Qnum": 52, "Question": "what are the bride and groom cutting?", "out": ["1. A group of images is provided.", "2. The bride and groom are seen cutting a cake together."], "CS_val": ["0.12683847546577454", "0.00018489100330043584"], "CS_val_2": ["0.12683847546577454", "0.00018489100330043584"], "img_dir": ["img_db_CS/image_qs52_0.png", "img_db_CS/image_qs52_1.png", "img_db_CS/image_qs52_2.png", "img_db_CS/image_qs52_3.png", "img_db_CS/image_qs52_4.png"]}, {"Qnum": 53, "Question": "what is the color of the sauce?", "out": ["1. The sauce in the images is red."], "CS_val": ["0.003068293444812298"], "CS_val_2": ["0.003068293444812298"], "img_dir": ["img_db_CS/image_qs53_0.png", "img_db_CS/image_qs53_1.png", "img_db_CS/image_qs53_2.png", "img_db_CS/image_qs53_3.png", "img_db_CS/image_qs53_4.png"]}, {"Qnum": 54, "Question": "the man riding what down a snow covered slope?", "out": ["1. The man is snowboarding down a snow-covered slope.", "2. He is enjoying the thrill of gliding down the slope.", "3. The man's snowboard is smoothly gliding on the snow."], "CS_val": ["3.6398996599018574e-05", "subjective", "0.04581727087497711"], "CS_val_2": ["3.6398996599018574e-05", "subjective", "0.04581727087497711"], "img_dir": ["img_db_CS/image_qs54_0.png", "img_db_CS/image_qs54_1.png", "img_db_CS/image_qs54_2.png", "img_db_CS/image_qs54_3.png", "img_db_CS/image_qs54_4.png"]}, {"Qnum": 55, "Question": "where is the woman with a newspaper sitting?", "out": ["1. A woman with a newspaper is sitting on a bench in a group of images.", "2. The woman is sitting on a bench while holding a newspaper.", "3. The woman in the group of images is sitting on a bench with a newspaper in her hand."], "CS_val": ["1.4793068658036646e-05", "0.00021707965061068535", "subjective"], "CS_val_2": ["1.4793068658036646e-05", "0.00021707965061068535", "0.0002623676264192909"], "img_dir": ["img_db_CS/image_qs55_0.png", "img_db_CS/image_qs55_1.png", "img_db_CS/image_qs55_2.png", "img_db_CS/image_qs55_3.png", "img_db_CS/image_qs55_4.png"]}, {"Qnum": 56, "Question": "what is being loaded for a trip?", "out": ["1. A large truck is carrying a boat across a bridge in a group of images.", "2. The boat is being transported by the large truck on the bridge.", "3. People are seen walking through a building with a variety of luggage.", "4. The group of people is moving through the building with their luggage.", "5. Suitcases and handbags are among the items in the luggage.", "6. The suitcases and handbags are part of the luggage being carried.", "7. The images indicate that the people are traveling to or from a trip.", "8. The people are shown either arriving or departing in the images.", "9. The luggage is waiting to be picked up or transported to another location.", "10. The luggage is waiting for pickup or to be transported to another place."], "CS_val": ["subjective", "0.010540716350078583", "subjective", "0.0006400475976988673", "subjective", "0.2168024778366089", "subjective", "0.00012097923900000751", "subjective", "0.0018812160706147552"], "CS_val_2": ["3.986042065662332e-05", "0.010540716350078583", "0.00030580165912397206", "0.0006400475976988673", "0.2516893148422241", "0.2168024778366089", "0.0005738621694035828", "0.00012097923900000751", "0.0011762796202674508", "0.0018812160706147552"], "img_dir": ["img_db_CS/image_qs56_0.png", "img_db_CS/image_qs56_1.png", "img_db_CS/image_qs56_2.png", "img_db_CS/image_qs56_3.png", "img_db_CS/image_qs56_4.png"]}, {"Qnum": 57, "Question": "what is yellow and white?", "out": ["1. Yellow and white flowers are in a vase on the dining table in a group of images.", "2. The yellow and white flowers can be found in the vase on the dining table.", "3. The flowers are specifically placed in a vase on the dining table.", "4. The flowers are a combination of yellow and white colors. ", "5. The flowers are contained within a vase.", "6. The vase is positioned on the dining table.", "7. The vase holds yellow and white flowers."], "CS_val": ["8.55426987982355e-05", "subjective", "subjective", "subjective", "subjective", "subjective", "subjective"], "CS_val_2": ["8.55426987982355e-05", "0.0011684696655720472", "0.0026179077103734016", "0.00032335135620087385", "0.004818308167159557", "0.0010067472467198968", "0.00012355847866274416"], "img_dir": ["img_db_CS/image_qs57_0.png", "img_db_CS/image_qs57_1.png", "img_db_CS/image_qs57_2.png", "img_db_CS/image_qs57_3.png", "img_db_CS/image_qs57_4.png"]}, {"Qnum": 58, "Question": "what is the man riding through a crowded intersection?", "out": ["A man is seen riding a horse in a busy intersection among a group of images."], "CS_val": ["1.2704162145382725e-05"], "CS_val_2": ["1.2704162145382725e-05"], "img_dir": ["img_db_CS/image_qs58_0.png", "img_db_CS/image_qs58_1.png", "img_db_CS/image_qs58_2.png", "img_db_CS/image_qs58_3.png", "img_db_CS/image_qs58_4.png"]}, {"Qnum": 59, "Question": "what near lounge chairs at the beach?", "out": ["1. <image3> shows a lounge chair positioned at the beach.", "2. The location is described as cozy and provides a great view of the ocean.", "3. The chair is facing the water, optimal for sunbathing.", "4. This spot is popular among beach visitors seeking a peaceful moment near the sea."], "CS_val": ["0.0003438554995227605", "subjective", "subjective", "subjective"], "CS_val_2": ["0.0003438554995227605", "subjective", "0.006207254249602556", "0.005468641873449087"], "img_dir": ["img_db_CS/image_qs59_0.png", "img_db_CS/image_qs59_1.png", "img_db_CS/image_qs59_2.png", "img_db_CS/image_qs59_3.png", "img_db_CS/image_qs59_4.png"]}, {"Qnum": 60, "Question": "what is the smiling group of dressed up people are eating?", "out": ["A group of people dressed up and smiling are eating cake in the images provided."], "CS_val": ["8.23339451017091e-06"], "CS_val_2": ["8.23339451017091e-06"], "img_dir": ["img_db_CS/image_qs60_0.png", "img_db_CS/image_qs60_1.png", "img_db_CS/image_qs60_2.png", "img_db_CS/image_qs60_3.png", "img_db_CS/image_qs60_4.png"]}, {"Qnum": 61, "Question": "what does the woman hold up in front of her face?", "out": ["The woman in the group of images is shown holding a cell phone in front of her face."], "CS_val": ["0.00013911962741985917"], "CS_val_2": ["0.00013911962741985917"], "img_dir": ["img_db_CS/image_qs61_0.png", "img_db_CS/image_qs61_1.png", "img_db_CS/image_qs61_2.png", "img_db_CS/image_qs61_3.png", "img_db_CS/image_qs61_4.png"]}, {"Qnum": 62, "Question": "what is sitting on the tree branch spreading its tail-feathers?", "out": ["1. The red cardinal bird in <image3> is perched on a tree branch and spreading its tail-feathers. ", "2. The bird in question is specifically identified as a red cardinal. ", "3. The red cardinal can be seen sitting on a tree branch. ", "4. The red cardinal is displaying its tail-feathers."], "CS_val": ["0.0024891034699976444", "subjective", "subjective", "subjective"], "CS_val_2": ["0.0024891034699976444", "0.9052924513816833", "0.541865348815918", "0.23806078732013702"], "img_dir": ["img_db_CS/image_qs62_0.png", "img_db_CS/image_qs62_1.png", "img_db_CS/image_qs62_2.png", "img_db_CS/image_qs62_3.png", "img_db_CS/image_qs62_4.png"]}, {"Qnum": 63, "Question": "what is the person in a hat riding?", "out": ["The person wearing a hat is skateboarding in the group of images."], "CS_val": ["4.302127126720734e-05"], "CS_val_2": ["4.302127126720734e-05"], "img_dir": ["img_db_CS/image_qs63_0.png", "img_db_CS/image_qs63_1.png", "img_db_CS/image_qs63_2.png", "img_db_CS/image_qs63_3.png", "img_db_CS/image_qs63_4.png"]}, {"Qnum": 64, "Question": "what is taking off into the sky with its landing gear still extended?", "out": ["1. A large airplane is shown in a group of images, taking off with its landing gear still extended into the sky.", "2. The airplane is in the initial phase of lifting off from the runway, indicated by the extended landing gear.", "3. The presence of the landing gear suggests that the aircraft has recently landed and is now beginning its ascent back into the sky."], "CS_val": ["0.0028507511597126722", "0.0833534374833107", "subjective"], "CS_val_2": ["0.0028507511597126722", "0.0833534374833107", "0.695869505405426"], "img_dir": ["img_db_CS/image_qs64_0.png", "img_db_CS/image_qs64_1.png", "img_db_CS/image_qs64_2.png", "img_db_CS/image_qs64_3.png", "img_db_CS/image_qs64_4.png"]}, {"Qnum": 65, "Question": "what are sleeping on the bed with a red bedspread?", "out": ["1. A baby is shown sleeping on a bed with a red bedspread in a group of images.", "2. The baby is peacefully sleeping on the bed with a red bedspread in the image.", "3. The baby is calmly resting on the bed with a red bedspread in the photo."], "CS_val": ["4.829555473406799e-05", "0.001071535749360919", "0.005153153091669083"], "CS_val_2": ["4.829555473406799e-05", "subjective", "subjective"], "img_dir": ["img_db_CS/image_qs65_0.png", "img_db_CS/image_qs65_1.png", "img_db_CS/image_qs65_2.png", "img_db_CS/image_qs65_3.png", "img_db_CS/image_qs65_4.png"]}, {"Qnum": 66, "Question": "where does the woman take a photo of herself?", "out": ["-The woman in the group of images takes a selfie in the first image."], "CS_val": ["0.003876469796523452"], "CS_val_2": ["0.003876469796523452"], "img_dir": ["img_db_CS/image_qs66_0.png", "img_db_CS/image_qs66_1.png", "img_db_CS/image_qs66_2.png", "img_db_CS/image_qs66_3.png", "img_db_CS/image_qs66_4.png"]}]